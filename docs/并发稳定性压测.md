# 并发稳定性压测（pub/sub + RPC）

目标：在不依赖业务服务的前提下，用“多 topic 状态订阅 + 多 RPC request/response 并发”压测 MotionCore 的执行器（Executor/Strand）与 RPC/订阅薄封装的稳定性。

本工具实现 5 个角色（每个角色一个进程）：
- `scheduler`：任务调度服务节点（订阅 4 个状态 topic，并向 4 个服务节点发起 RPC 请求获得响应）
- `luggage`：行李数据采集服务节点（发布自身状态 + 提供 RPC）
- `robot1`：1 号机器人服务节点（发布自身状态 + 提供 RPC）
- `localization1`：1 号定位检测服务节点（发布自身状态 + 提供 RPC）
- `pallet_logic1`：1 号码垛逻辑服务节点（发布自身状态 + 提供 RPC）

## 编译

说明：MotionCore 当前不再内置 `MotionCore/examples`（保持核心库干净）。

备注：历史上本仓库曾在 Workstation 侧提供过可运行的 `concurrency_stress` 5 进程压测节点与一键/soak 脚本；后续为保持工作空间更精简已移除。

## 运行（5 进程）

Workstation 侧的 5 进程版本采用独立可执行文件形式（scheduler + 4 服务），通过环境变量统一调参；具体命令与脚本见 Workstation 文档。

说明：
- 每个服务节点：发布 `/stress/<role>/status`（EventDTO，schema=`stress.status.v1`），并提供 RPC service `stress.<role>`：
  - `work`：历史单 op（保留兼容）
  - `get_status`：轻量查询服务侧观测到的状态序号
  - `plan_task`：短耗时（模拟规划/计算）
  - `execute_task`：较重耗时（模拟执行/设备访问）
- scheduler：订阅 4 个 status topic，同时对 4 个服务做 round-robin RPC 调用。

## 关键参数（并发/隔离）

- `WXZ_STRESS_SUB_GROUP=exclusive|reentrant`
  - `exclusive`：订阅回调走 Strand（串行域），模拟 MutuallyExclusive callback group
  - `reentrant`：订阅回调走 Executor（并行域），模拟 Reentrant callback group
- `WXZ_STRESS_SRV_GROUP=exclusive|reentrant`
  - `exclusive`：RPC handler 串行执行（更像“设备 SDK 串行访问”）
  - `reentrant`：RPC handler 并行执行（更像“纯计算/可并行服务”）

- `WXZ_STRESS_IO_THREADS`：RPC reply 与订阅 decode/回调投递使用的执行器线程数
- `WXZ_STRESS_CALL_THREADS`：scheduler 发起同步 RPC call 的线程池（专用，避免阻塞 IO 执行器导致死锁）
- `WXZ_STRESS_RPC_INFLIGHT`：scheduler 侧允许的最大 in-flight 调用数（背压阈值）
- `WXZ_STRESS_RPC_MODE=work|get_status|plan_task|execute_task|mixed`
  - 推荐用 `mixed`：更贴近“调度→多服务、多类型请求”的真实负载
- `WXZ_STRESS_RPC_PROFILE=none|by_service`
  - `none`：仅使用 `rpc_mode`
  - `by_service`：scheduler 按目标服务选择 op（robot1/pallet_logic1 偏 execute；localization1 偏 get_status；luggage 偏 plan）

## 输出指标（每秒一行）

示例输出（scheduler）：

- `status_pub_ok/status_pub_drop`：本进程 status 发布成功/失败计数
- `status_recv`：已接收的状态消息总数
- `status_lat_p50_ms/status_lat_p99_ms`：状态消息端到端延迟（基于 EventDTO.timestamp 的 epoch ms）
- `rpc_ok/rpc_timeout/rpc_err`：RPC 成功/超时/其他错误计数
- `rpc_inflight`：当前 in-flight 调用数
- `rpc_lat_p50_ms/rpc_lat_p99_ms`：RPC 往返延迟（call 发起到返回）
- `last_seq_<role>=N`：scheduler 观测到的各服务最后状态序号（用于判断“是否还在持续活跃”）

## 建议验收标准（LAN 开发场景）

以下标准以“开发机/工控机正常负载、局域网 DDS discovery 足够”的目标为前提；实际阈值可按硬件能力调整。

**基础稳定性（必过）**
- 连续运行 10 分钟以上：无崩溃、无死锁、进程可 Ctrl-C 正常退出
- scheduler 侧：`rpc_timeout + rpc_err` 占比 < 1%（在 `rpc_inflight` 不超过阈值的前提下）
- scheduler 侧：4 个 `last_seq_*` 持续递增（无长时间停滞，允许短暂抖动）

**并发可靠性（建议）**
- 在 `--rpc_hz 2000 --rpc_inflight 512 --call_threads 16 --io_threads 2` 下：
  - `rpc_lat_p99_ms` 稳定（不持续单调增长）
  - `rpc_timeout` 不出现“持续上升到明显错误比例”的趋势

**背压可观测（建议）**
- 将 `--call_max_queue` 调小或 `--rpc_inflight` 调大时：
  - `rpc_err` 会上升（call executor 队列拒绝），但系统仍可运行且可退出
  - 这属于“可预期的退化”，用于验证“系统不会静默卡死”

## 典型问题定位

- 若出现大量 `rpc_timeout`：
  - 先增大 `--io_threads`（RPC reply 处理线程）或降低 `--rpc_hz/--rpc_inflight`
  - 检查是否把同步 call 跑在与 RPC reply 相同的单线程执行器上（会造成自锁）

- 若 `status_lat_p99_ms` 很高：
  - 先检查 `--sub_group exclusive` 是否导致串行域拥塞
  - 调整 `--history_depth` 或切换 `--best_effort 1`（允许丢包换低延迟）

## Workstation 侧回归记录

如果在系统层面清理过 `/usr/local` 的旧 Fast-DDS/Fast-RTPS（2.6.x），建议在的业务/集成工程侧保留一套“多进程并发 + 同时 SIGINT 退出”的回归用例，用于验证 teardown 稳定性。
